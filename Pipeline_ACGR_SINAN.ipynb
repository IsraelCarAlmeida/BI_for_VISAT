{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação da biblioteca pysus"
      ],
      "metadata": {
        "id": "cl2jlHOItDq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV7_1QD0j9Mc",
        "outputId": "4e223d66-36df-4519-ded1-3eb7c113feeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysus\n",
            "  Downloading pysus-0.15.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting Unidecode<2.0.0,>=1.3.6 (from pysus)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting aioftp<0.22.0,>=0.21.4 (from pysus)\n",
            "  Downloading aioftp-0.21.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting bigtree<0.13.0,>=0.12.2 (from pysus)\n",
            "  Downloading bigtree-0.12.5-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting cffi==1.15.1 (from pysus)\n",
            "  Downloading cffi-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting dateparser<2.0.0,>=1.1.8 (from pysus)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting dbfread==2.0.7 (from pysus)\n",
            "  Downloading dbfread-2.0.7-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting elasticsearch==7.16.2 (from elasticsearch[preprocessing]==7.16.2->pysus)\n",
            "  Downloading elasticsearch-7.16.2-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting fastparquet>=2023.10.1 (from pysus)\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: humanize<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from pysus) (4.11.0)\n",
            "Collecting loguru<0.7.0,>=0.6.0 (from pysus)\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting numpy==1.26.2 (from pysus)\n",
            "  Downloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from pysus) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pysus) (17.0.0)\n",
            "Collecting pycparser==2.21 (from pysus)\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyreaddbc>=1.1.0 (from pysus)\n",
            "  Downloading pyreaddbc-1.2.0.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.11/dist-packages (from pysus) (2.8.2)\n",
            "Collecting tqdm==4.64.0 (from pysus)\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from pysus) (4.12.2)\n",
            "Collecting urwid<3.0.0,>=2.1.2 (from pysus)\n",
            "  Downloading urwid-2.6.16-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting wget<4.0,>=3.2 (from pysus)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3<2,>=1.21.1 (from elasticsearch==7.16.2->elasticsearch[preprocessing]==7.16.2->pysus)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from elasticsearch==7.16.2->elasticsearch[preprocessing]==7.16.2->pysus) (2024.12.14)\n",
            "\u001b[33mWARNING: elasticsearch 7.16.2 does not provide the extra 'preprocessing'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil==2.8.2->pysus) (1.17.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from dateparser<2.0.0,>=1.1.8->pysus) (2024.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.11/dist-packages (from dateparser<2.0.0,>=1.1.8->pysus) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser<2.0.0,>=1.1.8->pysus) (5.2)\n",
            "Collecting cramjam>=2.3 (from fastparquet>=2023.10.1->pysus)\n",
            "  Downloading cramjam-2.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet>=2023.10.1->pysus) (2024.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet>=2023.10.1->pysus) (24.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.2.2->pysus) (2024.2)\n",
            "Requirement already satisfied: pyyaml>=6 in /usr/local/lib/python3.11/dist-packages (from pyreaddbc>=1.1.0->pysus) (6.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from urwid<3.0.0,>=2.1.2->pysus) (0.2.13)\n",
            "Downloading pysus-0.15.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.6/462.6 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbfread-2.0.7-py2.py3-none-any.whl (20 kB)\n",
            "Downloading elasticsearch-7.16.2-py2.py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.7/385.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioftp-0.21.4-py3-none-any.whl (37 kB)\n",
            "Downloading bigtree-0.12.5-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urwid-2.6.16-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cramjam-2.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyreaddbc, wget\n",
            "  Building wheel for pyreaddbc (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyreaddbc: filename=pyreaddbc-1.2.0-cp311-cp311-manylinux_2_35_x86_64.whl size=89810 sha256=3b633ef0db3a4937807e6ff38325c7c37d3423f428b602b7851c5c0a2ff8ddfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/24/ff/03c9d6c394a14bf0f14a18333ff9345e8ff1bc3c62b10b399e\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=4219393e14683d13aa754d27cfedcede5d0ecf103f147919c96d4ec932cdf546\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built pyreaddbc wget\n",
            "Installing collected packages: wget, dbfread, urwid, urllib3, Unidecode, tqdm, pycparser, numpy, loguru, cramjam, bigtree, aioftp, elasticsearch, dateparser, cffi, pyreaddbc, fastparquet, pysus\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.22\n",
            "    Uninstalling pycparser-2.22:\n",
            "      Successfully uninstalled pycparser-2.22\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.17.1\n",
            "    Uninstalling cffi-1.17.1:\n",
            "      Successfully uninstalled cffi-1.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.0 requires tqdm>=4.64.1, but you have tqdm 4.64.0 which is incompatible.\n",
            "pygit2 1.16.0 requires cffi>=1.17.0, but you have cffi 1.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Unidecode-1.3.8 aioftp-0.21.4 bigtree-0.12.5 cffi-1.15.1 cramjam-2.9.1 dateparser-1.2.0 dbfread-2.0.7 elasticsearch-7.16.2 fastparquet-2024.11.0 loguru-0.6.0 numpy-1.26.2 pycparser-2.21 pyreaddbc-1.2.0 pysus-0.15.0 tqdm-4.64.0 urllib3-1.26.20 urwid-2.6.16 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "pip install pysus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA6dEJVPylkw",
        "outputId": "adb5567d-e429-49b9-e605-3130bc9cf4f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n"
          ]
        }
      ],
      "source": [
        "# Seleciona os anos que serão baixados\n",
        "years_for_donwload = [i for i in range(2007, 2024)]\n",
        "print(years_for_donwload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wkqHsO8vzd3E"
      },
      "outputs": [],
      "source": [
        "# Faz a importação da biblioteca e conecta com a ftp\n",
        "from pysus.ftp.databases.sinan import SINAN\n",
        "sinan = SINAN().load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMjOms2QFI87",
        "outputId": "f47e85a8-b46b-4540-d0b1-72f5ab883574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Caso seja necessário é possível conectar com o drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração e transformações iniciais"
      ],
      "metadata": {
        "id": "Ir_MwQ1yyrrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eryqohtemU85"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Cria a base cid-10\n",
        "cid_10 = pd.read_csv('/content/CID-10_Categorias.csv')\n",
        "cid_10['CAT'] = cid_10['CAT'].astype('str')\n",
        "\n",
        "cid_10_dict = {}\n",
        "\n",
        "for i in cid_10.values:\n",
        "  cid_10_dict[i[0][:3]] = i[1]\n",
        "\n",
        "# Função que recebe o código cid-10 e retorna a descrição\n",
        "def description_cid(cid_id):\n",
        "  if len(cid_id) >= 3:\n",
        "    cid_clean = cid_id[:3]\n",
        "    cid_description = cid_10_dict[cid_clean]\n",
        "\n",
        "  else:\n",
        "    cid_description = 'CID não registrado'\n",
        "\n",
        "  return cid_description\n",
        "\n",
        "\n",
        "# Cria a base com todos os municípios do Brasil\n",
        "municipios_BR = pd.read_csv('/content/municipios_BR.csv')\n",
        "municipios_BR['COD_MUN'] = municipios_BR['COD_MUN'].astype('str')\n",
        "\n",
        "municipios_BR_dict = {}\n",
        "\n",
        "for i in municipios_BR.values:\n",
        "  municipios_BR_dict[i[0][:6]] = i[1]\n",
        "\n",
        "\n",
        "# Cria a base com todos os estados do Brasil\n",
        "estados_BR_dict = {\n",
        "                   '11': 'Rondônia',\n",
        "                   '12': 'Acre',\n",
        "                   '13': 'Amazonas',\n",
        "                   '14': 'Roraima',\n",
        "                   '15': 'Pará',\n",
        "                   '16': 'Amapá',\n",
        "                   '17': 'Tocantins',\n",
        "                   '21': 'Maranhão',\n",
        "                   '22': 'Piauí',\n",
        "                   '23': 'Ceará',\n",
        "                   '24': 'Rio Grande do Norte',\n",
        "                   '25': 'Paraíba',\n",
        "                   '26': 'Pernambuco',\n",
        "                   '27': 'Alagoas',\n",
        "                   '28': 'Sergipe',\n",
        "                   '29': 'Bahia',\n",
        "                   '31': 'Minas Gerais',\n",
        "                   '32': 'Espírito Santo',\n",
        "                   '33': 'Rio de Janeiro',\n",
        "                   '35': 'São Paulo',\n",
        "                   '41': 'Paraná',\n",
        "                   '42': 'Santa Catarina',\n",
        "                   '43': 'Rio Grande do Sul',\n",
        "                   '50': 'Mato Grosso do Sul',\n",
        "                   '51': 'Mato Grosso',\n",
        "                   '52': 'Goiás',\n",
        "                   '53': 'Distrito Federal',\n",
        "}\n",
        "\n",
        "\n",
        "# Função que recebe um campo de data e retorna a mesma data em uma formatação amigável dia/mês/ano\n",
        "def format_data(data_var):\n",
        "  if len(str(data_var)) == 8:\n",
        "    data_result = f'{str(data_var)[6:10]}/{str(data_var)[4:6]}/{str(data_var)[0:4]}'\n",
        "\n",
        "  elif len(str(data_var)) == 10:\n",
        "    data_result =f'{str(data_var)[8:10]}/{str(data_var)[5:7]}/{str(data_var)[0:4]}'\n",
        "\n",
        "  else:\n",
        "    data_result = '31/12/1999'\n",
        "\n",
        "  return data_result\n",
        "\n",
        "\n",
        "# Função que recebe o ano do acidente e o ano de nascimento e retorna a idade\n",
        "def generate_age(ano_acidente, ano_nascimento):\n",
        "  try:\n",
        "    age = int(ano_acidente[6:10]) - int(ano_nascimento)\n",
        "\n",
        "  except:\n",
        "    age = 999\n",
        "\n",
        "  return age\n",
        "\n",
        "\n",
        "# Função que recebe a idade e retorna a faixa etária\n",
        "def generate_age_range(age_var):\n",
        "\n",
        "  if int(age_var) == 999:\n",
        "    age_range = 'Não possui'\n",
        "\n",
        "  elif int(age_var) < 0:\n",
        "    age_range = 'Idade menor que 0'\n",
        "\n",
        "  elif 0 <= int(age_var) <= 9:\n",
        "    age_range = '0 a 9 Anos'\n",
        "\n",
        "  elif 10 <= int(age_var) <= 19:\n",
        "    age_range = '10 a 19 Anos'\n",
        "\n",
        "  elif 20 <= int(age_var) <= 29:\n",
        "    age_range = '20 a 29 Anos'\n",
        "\n",
        "  elif 30 <= int(age_var) <= 39:\n",
        "    age_range = '30 a 39 Anos'\n",
        "\n",
        "  elif 40 <= int(age_var) <= 49:\n",
        "    age_range = '40 a 49 Anos'\n",
        "\n",
        "  elif 50 <= int(age_var) <= 59:\n",
        "    age_range = '50 a 59 Anos'\n",
        "\n",
        "  elif 60 <= int(age_var) <= 69:\n",
        "    age_range = '60 a 69 Anos'\n",
        "\n",
        "  elif 70 <= int(age_var) <= 79:\n",
        "    age_range = '70 a 79 Anos'\n",
        "\n",
        "  elif 80 <= int(age_var) <= 89:\n",
        "    age_range = '80 a 89 Anos'\n",
        "\n",
        "  elif 90 <= int(age_var):\n",
        "    age_range = '90 + Anos'\n",
        "\n",
        "  return age_range\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u02lkbegzojj",
        "outputId": "a7bdfc25-36f4-46c1-fda5-580b29183611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR07.parquet: 100%|██████████| 20.4k/20.4k [00:01<00:00, 10.9kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2007]: 19725\n",
            "Number of Columns [2007]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR08.parquet: 100%|██████████| 32.4k/32.4k [00:02<00:00, 11.9kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2008]: 31317\n",
            "Number of Columns [2008]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR09.parquet: 100%|██████████| 36.7k/36.7k [00:03<00:00, 12.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2009]: 35465\n",
            "Number of Columns [2009]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR10.parquet: 100%|██████████| 46.3k/46.3k [00:04<00:00, 11.0kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2010]: 44767\n",
            "Number of Columns [2010]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR11.parquet: 100%|██████████| 63.1k/63.1k [00:06<00:00, 10.4kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2011]: 60971\n",
            "Number of Columns [2011]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR12.parquet: 100%|██████████| 78.1k/78.1k [00:06<00:00, 12.8kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2012]: 75481\n",
            "Number of Columns [2012]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR13.parquet: 100%|██████████| 91.5k/91.5k [00:07<00:00, 12.0kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2013]: 88440\n",
            "Number of Columns [2013]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR14.parquet: 100%|██████████| 86.4k/86.4k [00:07<00:00, 11.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2014]: 83495\n",
            "Number of Columns [2014]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR15.parquet: 100%|██████████| 90.8k/90.8k [00:06<00:00, 13.0kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2015]: 87756\n",
            "Number of Columns [2015]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR16.parquet: 100%|██████████| 88.2k/88.2k [00:07<00:00, 11.0kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2016]: 85242\n",
            "Number of Columns [2016]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR17.parquet: 100%|██████████| 95.8k/95.8k [00:07<00:00, 12.4kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2017]: 92585\n",
            "Number of Columns [2017]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR18.parquet: 100%|██████████| 104k/104k [00:08<00:00, 11.7kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2018]: 100404\n",
            "Number of Columns [2018]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR19.parquet: 100%|██████████| 120k/120k [00:10<00:00, 11.7kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2019]: 116346\n",
            "Number of Columns [2019]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR20.parquet: 100%|██████████| 183k/183k [00:14<00:00, 12.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2020]: 176859\n",
            "Number of Columns [2020]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR21.parquet: 100%|██████████| 229k/229k [00:19<00:00, 11.7kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2021]: 221034\n",
            "Number of Columns [2021]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR22.parquet: 100%|██████████| 312k/312k [00:28<00:00, 11.0kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2022]: 301107\n",
            "Number of Columns [2022]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ACGRBR23.parquet: 100%|██████████| 459k/459k [00:39<00:00, 11.6kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Rows [2023]: 443470\n",
            "Number of Columns [2023]: 70\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Cria a pasta bronze\n",
        "dir_output = '/content/bronze'\n",
        "\n",
        "if os.path.isdir(dir_output):\n",
        "  shutil.rmtree(dir_output)\n",
        "else:\n",
        "  os.makedirs(dir_output)\n",
        "\n",
        "\n",
        "# Baixa os arquivos de cada ano, aplica algumas transformações e insere na pasta bronze\n",
        "for year in years_for_donwload:\n",
        "\n",
        "  data_year = sinan.get_files(year=year)\n",
        "\n",
        "  for file_name in data_year:\n",
        "\n",
        "    if str(file_name)[:4] == 'ACGR':\n",
        "\n",
        "      disease_accident = str(file_name)[:4]\n",
        "\n",
        "      generic_disease_accident = sinan.get_files(dis_code=disease_accident, year=[year])\n",
        "      download_disease_accident = sinan.download(generic_disease_accident)\n",
        "\n",
        "      disease_accident_df = download_disease_accident.to_dataframe()\n",
        "\n",
        "      disease_accident_df['cid_causa_acidente'] = list(map(description_cid, disease_accident_df['CID_ACID']))\n",
        "      disease_accident_df['data_notificacao'] = list(map(format_data, disease_accident_df['DT_NOTIFIC']))\n",
        "      disease_accident_df['data_acidente'] = list(map(format_data, disease_accident_df['DT_ACID']))\n",
        "      disease_accident_df['idade'] = list(map(generate_age, disease_accident_df['data_acidente'], disease_accident_df['ANO_NASC']))\n",
        "      disease_accident_df['faixa_etaria'] = list(map(generate_age_range, disease_accident_df['idade']))\n",
        "      disease_accident_df['data_atendimento_medico'] = list(map(format_data, disease_accident_df['DT_ATENDE']))\n",
        "      disease_accident_df['data_obito'] = list(map(format_data, disease_accident_df['DT_OBITO']))\n",
        "      disease_accident_df['estado_residencia'] = disease_accident_df.SG_UF.map(estados_BR_dict)\n",
        "      disease_accident_df['municipio_residencia'] = disease_accident_df.ID_MN_RESI.map(municipios_BR_dict)\n",
        "      disease_accident_df['estado_notificacao'] = disease_accident_df.SG_UF_NOT.map(estados_BR_dict)\n",
        "      disease_accident_df['municipio_notificacao'] = disease_accident_df.ID_MUNICIP.map(municipios_BR_dict)\n",
        "      disease_accident_df['estado_empresa'] = disease_accident_df.UF_EMP.map(estados_BR_dict)\n",
        "      disease_accident_df['municipio_empresa'] = disease_accident_df.MUN_EMP.map(municipios_BR_dict)\n",
        "      disease_accident_df['estado_acidente'] = disease_accident_df.UF_ACID.map(estados_BR_dict)\n",
        "      disease_accident_df['municipio_acidente'] = disease_accident_df.MUN_ACID.map(municipios_BR_dict)\n",
        "      disease_accident_df['estado_atendimento_medico'] = disease_accident_df.UF_ATENDE.map(estados_BR_dict)\n",
        "\n",
        "      print(f'\\nNumber of Rows [{year}]: {len(disease_accident_df.axes[0])}')\n",
        "      print(f'Number of Columns [{year}]: {len(disease_accident_df.axes[1])}\\n')\n",
        "\n",
        "      print(70 * '=')\n",
        "\n",
        "      disease_accident_df.to_parquet(f'{dir_output}/data_{year}.parquet')\n",
        "\n",
        "      original_file = f'/root/pysus/{str(generic_disease_accident)[1:9]}.parquet'\n",
        "\n",
        "      if os.path.isfile(original_file):\n",
        "        os.remove(original_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação do pyspark"
      ],
      "metadata": {
        "id": "rJs7x6BflJjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X-oHMEBMhgv"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Para acessar a versão mais recente: https://spark.apache.org/downloads.html\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz\n",
        "\n",
        "!tar xf spark-3.5.4-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.4-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QWkdMNiNctz"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NP5LpATE1Dc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName('VISAT') \\\n",
        "    .config('spark.ui.port', '4050') \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consolidação dos arquivos"
      ],
      "metadata": {
        "id": "2Zq5PIoSlivz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xSyjOhYCFECw",
        "outputId": "b2122ff3-c1f6-4c02-e92b-e64ef79e5574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows are: 2064464\n",
            "Number of Columns are: 70\n",
            "\n",
            "Schema:\n",
            "root\n",
            " |-- TP_NOT: string (nullable = true)\n",
            " |-- ID_AGRAVO: string (nullable = true)\n",
            " |-- DT_NOTIFIC: date (nullable = true)\n",
            " |-- SEM_NOT: string (nullable = true)\n",
            " |-- NU_ANO: string (nullable = true)\n",
            " |-- SG_UF_NOT: string (nullable = true)\n",
            " |-- ID_MUNICIP: string (nullable = true)\n",
            " |-- ID_REGIONA: string (nullable = true)\n",
            " |-- ID_UNIDADE: string (nullable = true)\n",
            " |-- DT_ACID: string (nullable = true)\n",
            " |-- SEM_ACID: string (nullable = true)\n",
            " |-- ANO_NASC: string (nullable = true)\n",
            " |-- NU_IDADE_N: string (nullable = true)\n",
            " |-- CS_SEXO: string (nullable = true)\n",
            " |-- CS_GESTANT: string (nullable = true)\n",
            " |-- CS_RACA: string (nullable = true)\n",
            " |-- CS_ESCOL_N: string (nullable = true)\n",
            " |-- SG_UF: string (nullable = true)\n",
            " |-- ID_MN_RESI: string (nullable = true)\n",
            " |-- ID_RG_RESI: string (nullable = true)\n",
            " |-- ID_PAIS: string (nullable = true)\n",
            " |-- ID_OCUPA_N: string (nullable = true)\n",
            " |-- SIT_TRAB: string (nullable = true)\n",
            " |-- NUTEMPO: string (nullable = true)\n",
            " |-- TPTEMPO: string (nullable = true)\n",
            " |-- LOCAL_ACID: string (nullable = true)\n",
            " |-- CNAE: string (nullable = true)\n",
            " |-- UF_EMP: string (nullable = true)\n",
            " |-- MUN_EMP: string (nullable = true)\n",
            " |-- TERCEIRIZA: string (nullable = true)\n",
            " |-- CNAE_PRIN: string (nullable = true)\n",
            " |-- HORA_ACID: string (nullable = true)\n",
            " |-- MIN_ACID: string (nullable = true)\n",
            " |-- HORA_JOR: string (nullable = true)\n",
            " |-- MIN_JOR: string (nullable = true)\n",
            " |-- UF_ACID: string (nullable = true)\n",
            " |-- MUN_ACID: string (nullable = true)\n",
            " |-- CID_ACID: string (nullable = true)\n",
            " |-- TIPO_ACID: string (nullable = true)\n",
            " |-- MAIS_TRAB: string (nullable = true)\n",
            " |-- NU_TRAB: string (nullable = true)\n",
            " |-- ATENDE_MED: string (nullable = true)\n",
            " |-- DT_ATENDE: string (nullable = true)\n",
            " |-- UF_ATENDE: string (nullable = true)\n",
            " |-- MUN_ATENDE: string (nullable = true)\n",
            " |-- UNI_ATENDE: string (nullable = true)\n",
            " |-- PART_CORP1: string (nullable = true)\n",
            " |-- PART_CORP2: string (nullable = true)\n",
            " |-- PART_CORP3: string (nullable = true)\n",
            " |-- CID_LESAO: string (nullable = true)\n",
            " |-- REGIME: string (nullable = true)\n",
            " |-- EVOLUCAO: string (nullable = true)\n",
            " |-- DT_OBITO: string (nullable = true)\n",
            " |-- CAT: string (nullable = true)\n",
            " |-- cid_causa_acidente: string (nullable = true)\n",
            " |-- data_notificacao: string (nullable = true)\n",
            " |-- data_acidente: string (nullable = true)\n",
            " |-- idade: long (nullable = true)\n",
            " |-- faixa_etaria: string (nullable = true)\n",
            " |-- data_atendimento_medico: string (nullable = true)\n",
            " |-- data_obito: string (nullable = true)\n",
            " |-- estado_residencia: string (nullable = true)\n",
            " |-- municipio_residencia: string (nullable = true)\n",
            " |-- estado_notificacao: string (nullable = true)\n",
            " |-- municipio_notificacao: string (nullable = true)\n",
            " |-- estado_empresa: string (nullable = true)\n",
            " |-- municipio_empresa: string (nullable = true)\n",
            " |-- estado_acidente: string (nullable = true)\n",
            " |-- municipio_acidente: string (nullable = true)\n",
            " |-- estado_atendimento_medico: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Lê os arquivos da bronze, consolida-os em um único arquivo e salva na silver\n",
        "df = spark.read.parquet(dir_output)\n",
        "\n",
        "silver = '/content/silver/'\n",
        "\n",
        "df.repartition(1).write.save(silver, format='parquet')\n",
        "\n",
        "for file in os.listdir(silver):\n",
        "    if file.endswith('.parquet'):\n",
        "      df_rd = spark.read.format('parquet').load(f'{silver}{file}')\n",
        "\n",
        "print(f'Number of Rows are: {df_rd.count()}')\n",
        "print(f'Number of Columns are: {len(df_rd.columns)}\\n')\n",
        "\n",
        "print(f'Schema:')\n",
        "df_rd.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformações finais"
      ],
      "metadata": {
        "id": "k7MHkhCCoO5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RpQHziXnxPEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262e095c-2d55-4739-985e-77923bc74a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows are: 2064464\n",
            "Number of Columns are: 82\n",
            "\n",
            "Schema:\n",
            "root\n",
            " |-- TP_NOT: string (nullable = true)\n",
            " |-- ID_AGRAVO: string (nullable = true)\n",
            " |-- DT_NOTIFIC: date (nullable = true)\n",
            " |-- SEM_NOT: string (nullable = true)\n",
            " |-- NU_ANO: string (nullable = true)\n",
            " |-- SG_UF_NOT: string (nullable = true)\n",
            " |-- ID_MUNICIP: string (nullable = true)\n",
            " |-- ID_REGIONA: string (nullable = true)\n",
            " |-- ID_UNIDADE: string (nullable = true)\n",
            " |-- DT_ACID: string (nullable = true)\n",
            " |-- SEM_ACID: string (nullable = true)\n",
            " |-- ANO_NASC: string (nullable = true)\n",
            " |-- NU_IDADE_N: string (nullable = true)\n",
            " |-- CS_SEXO: string (nullable = true)\n",
            " |-- CS_GESTANT: string (nullable = true)\n",
            " |-- CS_RACA: string (nullable = true)\n",
            " |-- CS_ESCOL_N: string (nullable = true)\n",
            " |-- SG_UF: string (nullable = true)\n",
            " |-- ID_MN_RESI: string (nullable = true)\n",
            " |-- ID_RG_RESI: string (nullable = true)\n",
            " |-- ID_PAIS: string (nullable = true)\n",
            " |-- ID_OCUPA_N: string (nullable = true)\n",
            " |-- SIT_TRAB: string (nullable = true)\n",
            " |-- NUTEMPO: string (nullable = true)\n",
            " |-- TPTEMPO: string (nullable = true)\n",
            " |-- LOCAL_ACID: string (nullable = true)\n",
            " |-- CNAE: string (nullable = true)\n",
            " |-- UF_EMP: string (nullable = true)\n",
            " |-- MUN_EMP: string (nullable = true)\n",
            " |-- TERCEIRIZA: string (nullable = true)\n",
            " |-- CNAE_PRIN: string (nullable = true)\n",
            " |-- HORA_ACID: string (nullable = true)\n",
            " |-- MIN_ACID: string (nullable = true)\n",
            " |-- HORA_JOR: string (nullable = true)\n",
            " |-- MIN_JOR: string (nullable = true)\n",
            " |-- UF_ACID: string (nullable = true)\n",
            " |-- MUN_ACID: string (nullable = true)\n",
            " |-- CID_ACID: string (nullable = true)\n",
            " |-- TIPO_ACID: string (nullable = true)\n",
            " |-- MAIS_TRAB: string (nullable = true)\n",
            " |-- NU_TRAB: string (nullable = true)\n",
            " |-- ATENDE_MED: string (nullable = true)\n",
            " |-- DT_ATENDE: string (nullable = true)\n",
            " |-- UF_ATENDE: string (nullable = true)\n",
            " |-- MUN_ATENDE: string (nullable = true)\n",
            " |-- UNI_ATENDE: string (nullable = true)\n",
            " |-- PART_CORP1: string (nullable = true)\n",
            " |-- PART_CORP2: string (nullable = true)\n",
            " |-- PART_CORP3: string (nullable = true)\n",
            " |-- CID_LESAO: string (nullable = true)\n",
            " |-- REGIME: string (nullable = true)\n",
            " |-- EVOLUCAO: string (nullable = true)\n",
            " |-- DT_OBITO: string (nullable = true)\n",
            " |-- CAT: string (nullable = true)\n",
            " |-- cid_causa_acidente: string (nullable = true)\n",
            " |-- data_notificacao: string (nullable = true)\n",
            " |-- data_acidente: string (nullable = true)\n",
            " |-- idade: long (nullable = true)\n",
            " |-- faixa_etaria: string (nullable = true)\n",
            " |-- data_atendimento_medico: string (nullable = true)\n",
            " |-- data_obito: string (nullable = true)\n",
            " |-- estado_residencia: string (nullable = true)\n",
            " |-- municipio_residencia: string (nullable = true)\n",
            " |-- estado_notificacao: string (nullable = true)\n",
            " |-- municipio_notificacao: string (nullable = true)\n",
            " |-- estado_empresa: string (nullable = true)\n",
            " |-- municipio_empresa: string (nullable = true)\n",
            " |-- estado_acidente: string (nullable = true)\n",
            " |-- municipio_acidente: string (nullable = true)\n",
            " |-- estado_atendimento_medico: string (nullable = true)\n",
            " |-- sexo: string (nullable = true)\n",
            " |-- gestante: string (nullable = true)\n",
            " |-- raca_cor: string (nullable = true)\n",
            " |-- escolaridade: string (nullable = true)\n",
            " |-- ocupacao_grande_grupo: string (nullable = true)\n",
            " |-- situacao_trabalho: string (nullable = true)\n",
            " |-- tipo_acidente: string (nullable = true)\n",
            " |-- atendimento_medico: string (nullable = true)\n",
            " |-- evolucao_caso: string (nullable = true)\n",
            " |-- comunicacao_acidente_trabalho: string (nullable = true)\n",
            " |-- local_acidente: string (nullable = true)\n",
            " |-- local_tratamento: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, col, substring\n",
        "\n",
        "\n",
        "# Lê o arquivo da silver, aplica diversas transformações e salva na gold\n",
        "for file in os.listdir(silver):\n",
        "    if file.endswith('.parquet'):\n",
        "      df_compiled = spark.read.parquet(f'{silver}{file}')\n",
        "\n",
        "df_compiled = df_compiled.select(col('*'),\\\n",
        "                   when(df_compiled.CS_SEXO == 'F', 'Feminino')\\\n",
        "                  .when(df_compiled.CS_SEXO == 'M', 'Masculino')\\\n",
        "                  .when(df_compiled.CS_SEXO == 'I', 'Ignorado')\\\n",
        "                  .when(df_compiled.CS_SEXO == '', 'Em branco')\\\n",
        "                  .when(df_compiled.CS_SEXO.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.CS_SEXO).alias('sexo'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.CS_GESTANT == '1', '1º Trimestre')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '2', '2º Trimestre')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '3', '3º Trimestre')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '4', 'Idade gestacional Ignorada')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '5', 'Não')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '6', 'Não se aplica')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.CS_GESTANT == '', 'Em branco')\\\n",
        "                  .when(df_compiled.CS_GESTANT.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.CS_GESTANT).alias('gestante'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.CS_RACA == '1', 'Branca')\\\n",
        "                  .when(df_compiled.CS_RACA == '2', 'Preta')\\\n",
        "                  .when(df_compiled.CS_RACA == '3', 'Amarela')\\\n",
        "                  .when(df_compiled.CS_RACA == '4', 'Parda')\\\n",
        "                  .when(df_compiled.CS_RACA == '5', 'Indígena')\\\n",
        "                  .when(df_compiled.CS_RACA == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.CS_RACA == '', 'Em branco')\\\n",
        "                  .when(df_compiled.CS_RACA.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.CS_RACA).alias('raca_cor'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.CS_ESCOL_N == '00', 'Analfabeto')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '01', '1ª a 4ª série incompleta do EF (antigo primário ou 1º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '02', '4ª série completa do EF (antigo primário ou 1º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '3 ', '5ª à 8ª série incompleta do EF (antigo ginásio ou 1º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '03', '5ª à 8ª série incompleta do EF (antigo ginásio ou 1º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '04', 'Ensino fundamental completo (antigo ginásio ou 1º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '05', 'Ensino médio incompleto (antigo colegial ou 2º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '06', 'Ensino médio completo (antigo colegial ou 2º grau)')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '07', 'Educação superior incompleta')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '08', 'Educação superior completa')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '09', 'Ignorado')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '10', 'Não se aplica')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N == '', 'Em branco')\\\n",
        "                  .when(df_compiled.CS_ESCOL_N.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.CS_ESCOL_N).alias('escolaridade'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '0', 'Forças Armadas, Policiais e Bombeiros Militares')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '1', 'Membros superiores do poder público, dirigentes de organizações')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '2', 'Profissionais das ciências e das artes')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '3', 'Técnicos de nível médio')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '4', 'Trabalhadores de serviços administrativos')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '5', 'Trabalhadores dos serviços, vendedores do comércio em lojas e mercados')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '6', 'Trabalhadores agropecuários, florestais, da caça e pesca')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '7', 'Trabalhadores da produção de bens e serviços industriais')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '8', 'Trabalhadores da produção de bens e serviços industriais')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '9', 'Trabalhadores de manutenção e reparação')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1) == '', 'Em branco')\\\n",
        "                  .when(substring(df_compiled.ID_OCUPA_N, 1, 1).isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.ID_OCUPA_N).alias('ocupacao_grande_grupo'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.SIT_TRAB == '1 ', 'Empregado registrado com carteira assinada')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '01', 'Empregado registrado com carteira assinada')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '02', 'Empregado não registrado')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '03', 'Autônomo/conta própria')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '04', 'Servidor público estatuário')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '05', 'Servidor público celetista')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '06', 'Aposentado')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '07', 'Desempregado')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '08', 'Trabalho temporário')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '09', 'Cooperativado')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '10', 'Trabalhador avulso')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '11', 'Empregador')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '12', 'Outros')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '99', 'Ignorado')\\\n",
        "                  .when(df_compiled.SIT_TRAB == '', 'Em branco')\\\n",
        "                  .when(df_compiled.SIT_TRAB.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.SIT_TRAB).alias('situacao_trabalho'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.TIPO_ACID == '1', 'Típico')\\\n",
        "                  .when(df_compiled.TIPO_ACID == '2', 'Trajeto')\\\n",
        "                  .when(df_compiled.TIPO_ACID == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.TIPO_ACID == '', 'Em branco')\\\n",
        "                  .when(df_compiled.TIPO_ACID.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.TIPO_ACID).alias('tipo_acidente'))\\\n",
        "                  \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.ATENDE_MED == '1', 'Sim')\\\n",
        "                  .when(df_compiled.ATENDE_MED == '2', 'Não')\\\n",
        "                  .when(df_compiled.ATENDE_MED == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.ATENDE_MED == '', 'Em branco')\\\n",
        "                  .when(df_compiled.ATENDE_MED.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.ATENDE_MED).alias('atendimento_medico'))\\\n",
        "                   \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.EVOLUCAO == '1', 'Cura')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '2', 'Incapacidade temporária')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '3', 'Incapacidade parcial permanente')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '4', 'Incapacidade total permanente')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '5', 'Óbito por acidente de trabalho grave')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '6', 'Óbito por outras causas')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '7', 'Outro')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '8', 'Não identificado')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.EVOLUCAO == '', 'Em branco')\\\n",
        "                  .when(df_compiled.EVOLUCAO.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.EVOLUCAO).alias('evolucao_caso'))\\\n",
        "                   \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.CAT == '1', 'Sim')\\\n",
        "                  .when(df_compiled.CAT == '2', 'Não')\\\n",
        "                  .when(df_compiled.CAT == '3', 'Não se aplica')\\\n",
        "                  .when(df_compiled.CAT == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.CAT == '', 'Em branco')\\\n",
        "                  .when(df_compiled.CAT.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.CAT).alias('comunicacao_acidente_trabalho'))\\\n",
        "                   \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.LOCAL_ACID == '1', 'Instalações do Contratante')\\\n",
        "                  .when(df_compiled.LOCAL_ACID == '2', 'Via Pública')\\\n",
        "                  .when(df_compiled.LOCAL_ACID == '3', 'Instalações de terceiros')\\\n",
        "                  .when(df_compiled.LOCAL_ACID == '4', 'Domicílio próprio')\\\n",
        "                  .when(df_compiled.LOCAL_ACID == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.LOCAL_ACID == '', 'Em branco')\\\n",
        "                  .when(df_compiled.LOCAL_ACID.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.LOCAL_ACID).alias('local_acidente'))\\\n",
        "                   \\\n",
        "                  .select(col('*'),\\\n",
        "                   when(df_compiled.REGIME == '1', 'Hospitalar')\\\n",
        "                  .when(df_compiled.REGIME == '2', 'Ambulatório')\\\n",
        "                  .when(df_compiled.REGIME == '3', 'Ambos')\\\n",
        "                  .when(df_compiled.REGIME == '9', 'Ignorado')\\\n",
        "                  .when(df_compiled.REGIME == '', 'Em branco')\\\n",
        "                  .when(df_compiled.REGIME.isNull(), 'Em branco')\\\n",
        "                  .otherwise(df_compiled.REGIME).alias('local_tratamento'))\n",
        "\n",
        "\n",
        "print(f'Number of Rows are: {df_compiled.count()}')\n",
        "print(f'Number of Columns are: {len(df_compiled.columns)}\\n')\n",
        "\n",
        "print(f'Schema:')\n",
        "df_compiled.printSchema()\n",
        "\n",
        "df_compiled.repartition(1).write.save('/content/gold/', format='parquet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Orientações finais"
      ],
      "metadata": {
        "id": "l2gFq0w5sSd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a finalização do fluxo, baixe o arquivo que está na gold e renomeie para \"ACGR_2007_2023_ouro.parquet\".\n",
        "\n",
        "Clicando no símbolo de uma pasta do lado esquerdo vão ser exibidas as pastas do projeto, clicando nos três pontinhos ao lado de cada arquivo irá ser exibida a opção de baixá-lo."
      ],
      "metadata": {
        "id": "bOAzIvAbqNUL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}